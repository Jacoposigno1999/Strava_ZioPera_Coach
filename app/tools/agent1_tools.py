from datapizza.tools import tool
from Scripts.domain.models import UserStats, TrainingPlan
import psycopg2
from psycopg2.extras import RealDictCursor
from dotenv import load_dotenv
import os 
load_dotenv()
import json 
# In a real app, you would import your DB repository here


# TODO: Move DB connection logic to a shared utils file
def get_db_connection():
    """Establishes connection to the Postgres DB."""
    return psycopg2.connect(
        database=os.getenv("POSTGRES_DB"),
        user=os.getenv("POSTGRES_USER"),
        password=os.getenv("POSTGRES_PASSWORD"),
        host=os.getenv("POSTGRES_HOST"),
        port=os.getenv("POSTGRES_PORT")
    )

@tool
def get_runner_stats(user_id: str) -> str:
    """
    Fetches REAL historical performance from the Postgres 'activities' table.
    Calculates:
    1. Average Weekly Volume (last 4 weeks).
    2. Estimated 5k time (based on fastest recent run).
    """
    conn = None
    try:
        conn = get_db_connection()
        cur = conn.cursor()

        # --- METRIC 1: AVERAGE WEEKLY VOLUME (Last 28 Days) ---
        # Logic: Sum distance of all runs in last 28 days, divide by 4.
        query_vol = """
            SELECT SUM(distance_m) as total_dist
            FROM activities 
            WHERE (type ILIKE '%Run%' OR sport_type ILIKE '%Run%')
            AND start_date_local >= NOW() - INTERVAL '28 days';
        """
        cur.execute(query_vol)
        result_vol = cur.fetchone()
        
        total_meters = result_vol[0] if result_vol and result_vol[0] else 0
        avg_weekly_km = (total_meters / 1000.0) / 4.0

        # --- METRIC 2: RECENT 5K TIME (Proxy for Fitness) ---
        # Logic: Find the fastest run >= 5km in the last 90 days.
        # We use average_speed_mps (meters per second) to calculate 5k time.
        query_speed = """
            SELECT average_speed_mps 
            FROM activities 
            WHERE (type ILIKE '%Run%' OR sport_type ILIKE '%Run%')
            AND distance_m >= 5000 
            AND start_date_local >= NOW() - INTERVAL '90 days'
            ORDER BY average_speed_mps DESC
            LIMIT 1;
        """
        cur.execute(query_speed)
        result_speed = cur.fetchone()

        if result_speed and result_speed[0]:
            speed_mps = result_speed[0]
            # Time = Distance / Speed
            # 5000m / speed (m/s) = seconds. / 60 = minutes.
            est_5k_time_min = (5000 / speed_mps) / 60
        else:
            # Fallback if no recent data found
            #TODO: Return a message indicating lack of data
            est_5k_time_min = 30.0 # Default fallback

        # --- CONSTRUCT OBJECT ---
        # Note: 'Age' is not in the activities table. 
        # Ideally, we would fetch this from a 'users' table. 
        # For now, we default to 30 or pass a placeholder.
        real_stats = UserStats(
            user_id=user_id,
            age=30, # Limitation: Data not in DB yet
            avg_weekly_km=round(avg_weekly_km, 2),
            recent_5k_time_min=round(est_5k_time_min, 1),
            injury_status="None" 
        )
        
        print(f"üìä [DB READ] Stats loaded for {user_id}: {real_stats.avg_weekly_km} km/wk, 5k est: {real_stats.recent_5k_time_min} min")
        return real_stats.model_dump_json()

    except Exception as e:
        return f"Error fetching stats: {str(e)}"
    finally:
        if conn:
            conn.close()



# TODO: Understand how to check if the plan_data generated from the LLM is valid JSON

@tool
def save_training_plan(plan_data: str) -> str:
    """
    Saves a generated training plan to the PostgreSQL database.
    Input 'plan_data' must be a valid JSON string with structure:
    {
      "user_id": "user_123",
      "goal_description": "10k in 45m",
      "workouts": [
         {"date": "2026-01-01", "type": "Run", "distance_km": 5.0, "pace": "5:00", "description": "Easy run"}
      ]
    }
    """
    conn = None
    try:
        # 1. Parse the Input JSON
        try:
            data = json.loads(plan_data)
        except json.JSONDecodeError:
            return "Error: Input was not valid JSON."

        user_id = data.get("user_id")
        workouts = data.get("workouts", []) 

        if not user_id or not workouts:
            return "Error: JSON missing 'user_id' or 'workouts' list."

        # 2. Sort workouts to determine start/end dates for the plan header
        # We assume the AI put dates in "YYYY-MM-DD" format --> TODO Validate this
        sorted_workouts = sorted(workouts, key=lambda x: x.get('date', '9999-12-31'))
        start_date = sorted_workouts[0].get('date')
        end_date = sorted_workouts[-1].get('date')

        conn = get_db_connection()
        cur = conn.cursor()

        # 3. Insert the PLAN (Header)
        # We use RETURNING plan_id to get the ID generated by Postgres
        insert_plan_query = """
            INSERT INTO training_plans (user_id, goal_description, start_date, end_date)
            VALUES (%s, %s, %s, %s)
            RETURNING plan_id;
        """
        cur.execute(insert_plan_query, (
            user_id, 
            data.get("goal_description", "Custom AI Plan"), 
            start_date, 
            end_date
        ))
        
        plan_id = cur.fetchone()[0] # Capture the new ID

        # 4. Prepare Workouts for Bulk Insert
        workout_tuples = []
        for w in workouts:
            workout_tuples.append((
                plan_id,
                user_id,
                w.get('date'),
                w.get('type', 'Run'),
                float(w.get('distance_km', 0)),
                w.get('pace', ''), # Matches 'target_pace_min_per_km'
                w.get('description', '')
            ))

        # 5. Insert WORKOUTS (Details)
        insert_workouts_query = """
            INSERT INTO workouts 
            (plan_id, user_id, scheduled_date, workout_type, distance_km, target_pace_min_per_km, description)
            VALUES (%s, %s, %s, %s, %s, %s, %s);
        """
        
        # executemany is optimized for bulk inserts
        cur.executemany(insert_workouts_query, workout_tuples)

        # 6. Commit the Transaction
        conn.commit()
        
        success_msg = f"‚úÖ Success: Saved Plan ID {plan_id} with {len(workouts)} workouts."
        print(f"üíæ [DB WRITE] {success_msg}")
        return success_msg

    except Exception as e:
        if conn:
            conn.rollback() # Undo partial changes if something failed
        error_msg = f"‚ùå Database Error: {str(e)}"
        print(error_msg)
        return error_msg
        
    finally:
        if conn:
            conn.close()

    